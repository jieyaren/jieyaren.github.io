---
layout: post
title: grpc介绍以及原理
categories: [language]
tags: [rpc]
---



> [介绍ppt](https://platformlab.stanford.edu/Seminar%20Talks/gRPC.pdf)，需要了解protobuf的相关概念



整体架构如图

<img src="https://wanghenshui.github.io/assets/image-20201204104843820.png" alt="image-20201204104843820" style="zoom:50%;" />



底层通过http2传输，也就带了流式传输功能 单向流双向流，只要proto消息带上 stream修饰符就行了

```protobuf
service Greeter {
  rpc SayHello3 (stream HelloRequest) returns (stream HelloReply) {}
}
```

http2是必要的么？还是google内网服务全体推http2？所有服务全切到http？如果存量服务没有怎么办？http2能带来哪些优点？

- 针对http1 链接共享，数据压缩，流量控制，低延迟，还支持流式

[官方回应](https://github.com/grpc/grpc/issues/6292) 

> HTTP2 is used for many good reasons: HTTP2 is a standard and HTTP  protocol is well known to proxies, firewalls and many software tools.  The streaming nature of HTTP2 suits our needs very well, so no need to  reinvent the wheel.



感觉还是主推http2， google没有内部各种各样的协议交互的问题

直接基于tcp socket或者websocket一样性能不差，我猜google内部组件对接上都推http就没有考虑这些方案



使用接口

- 同步一元调用 Unary 	/流式 stream
  - 一元调用就是request respons one shot的形式，流式就是一个弱化的tcp流的感觉
- 异步，得用个消费队列来接收消息

```c++
// 记录每个 AsyncSayHello 调用的信息
struct AsyncClientCall {
    HelloReply reply;
    ClientContext context;
    Status status;
    std::unique_ptr<ClientAsyncResponseReader<HelloReply>> response_reader;
};
class GreeterClient 
{
public:
    GreeterClient(std::shared_ptr<Channel> channel)
        : stub_(Greeter::NewStub(channel)) {}
    void SayHello(const std::string& user) 
    {
        HelloRequest request;
        request.set_name(user);
        AsyncClientCall* call = new AsyncClientCall;
        // 异步调用，非阻塞
        call->response_reader = stub_->AsyncSayHello(&call->context, request, &cq_);
        // 当 RPC 调用结束时，让 gRPC 自动将返回结果填充到 AsyncClientCall 中
        // 并将 AsyncClientCall 的地址加入到队列中
        call->response_reader->Finish(&call->reply, &call->status, (void*)call);
    }
    void AsyncCompleteRpc() 
    {
        void* got_tag;
        bool ok = false;
        // 从队列中取出 AsyncClientCall 的地址，会阻塞
        while (cq_.Next(&got_tag, &ok)) 
        {
            AsyncClientCall* call = static_cast<AsyncClientCall*>(got_tag);
            if (call->status.ok())
                std::cout << "Greeter received: " << call->reply.message() << std::endl;
            else
                std::cout << "RPC failed" << std::endl;
			
            delete call;  // 销毁对象 
        }
    }
private:
    std::unique_ptr<Greeter::Stub> stub_;
    CompletionQueue cq_;    // 队列
};
int main()
{
    auto channel = grpc::CreateChannel("localhost:5000", grpc::InsecureChannelCredentials());
    GreeterClient greeter(channel);
    // 启动新线程，从队列中取出结果并处理
    std::thread thread_ = std::thread(&GreeterClient::AsyncCompleteRpc, &greeter);
    for (int i = 0; i < 100; i++) {
        auto user = std::string("hello-world-") + std::to_string(i);
        greeter.SayHello(user);
    }
    return 0;
}
```



~~不像trpc会生成异步的客户端代码，future/promise~~



rpc从简单到复杂

从 `服务端注册函数，客户端调用名字对应的函数`演化成 `定义IDL文件描述接口，服务端实现接口，客户端调用接口` ,名字-函数注册信息全部隐藏在框架背后，并且，接口参数复杂化 

protobuf或者thift能提供接口参数的codegen/parse 



最简单的rpc ，拿[nanorpc](https://github.com/tdv/nanorpc)举例子

服务端，注册函数名字 函数（存一个map）

```c++
auto server = nanorpc::http::easy::make_server("0.0.0.0", "55555", 8, "/api/",
                                               std::pair{"test", [] (std::string const &s) { return "Tested: " + s; } }
                                              );

std::cout << "Press Enter for quit." << std::endl;
std::cin.get();
```

客户端，调用名字函数

```c++
auto client = nanorpc::http::easy::make_client("localhost", "55555", 8, "/api/");
std::string result = client.call("test", std::string{"test"});
std::cout << "Response from server: " << result << std::endl;
```

中间有个解析组件，把客户端发的函数名和参数拿到，从函数map里拿到函数，调用，结束



grpc这些框架，如何处理这些步骤？

首先，函数表，框架自身保存好，生成接口函数，既然客户端都直接调用接口函数了，这还算rpc么？

框架的客户端调用大多是这个样子的 [grpc cpp](https://zhuanlan.zhihu.com/p/53367817)为例子

```cpp
 Status status = stub_->SayHello(&context, request, &reply);
```

生成的客户端接口和服务端的实现接口不一样，代码生成会生成一个代理类(stub), 中间框架自身根据注册信息和context调用服务端的实现，只有request response是完全一致的，函数是不一致的



[smfrpc](https://github.com/smfrpc/smf )框架的codegen很有意思，有机会可以[研究一下](https://smfrpc.github.io/smf/)

---

### ref

- 知乎有个专栏，列了很多，可以参考 https://www.zhihu.com/column/c_1099707347118718976
- https://colobu.com/2017/04/06/dive-into-gRPC-streaming/
- 一篇grpc-go的分析 https://segmentfault.com/a/1190000019608421
- protobuf指南 https://blog.csdn.net/u011518120/article/details/54604615
- 一个future-promise rpc https://github.com/loveyacper/ananas/blob/master/docs/06_protobuf_rpc.md
- 腾讯的phxrpc https://github.com/Tencent/phxrpc
- 腾讯的tarsrpc 腾讯rpc真多啊 https://github.com/TarsCloud/TarsCpp

---

看到这里或许你有建议或者疑问或者指出我的错误，请留言评论或者邮件mailto:wanghenshui@qq.com, 多谢! 
<details>
<summary>觉得写的不错可以点开扫码赞助几毛</summary>
<img src="https://wanghenshui.github.io/assets/wepay.png" alt="微信转账">
</details>